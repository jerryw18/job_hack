{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHtI7gOYi3Y6+h2U3//oKw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jerryw18/job_hack/blob/main/JW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYVLekbwUj6w"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install uv\n",
        "# !uv pip install --system -qU llama-index==0.11.6 llama-index-llms-openai llama-index-readers-file llama-index-embeddings-openai llama-index-llms-openai-like \"openinference-instrumentation-llama-index>=2\" arize-phoenix python-dotenv\n"
      ],
      "metadata": {
        "id": "kVVWxBR9VI39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import environ from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "OPENAI_API_KEY = environ[\"OPENAI_API_KEY\"]"
      ],
      "metadata": {
        "id": "MBebwqCblW3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import (\n",
        "    SimpleDirectoryReader,\n",
        "    VectorStoreIndex,\n",
        "    StorageContext,\n",
        "    load_index_from_storage,\n",
        ")\n",
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "from llama_index.core.agent import ReActAgent\n",
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "\n",
        "# Create an llm object to use for the QueryEngine and the ReActAgent\n",
        "llm = OpenAI(model=\"gpt-4\")"
      ],
      "metadata": {
        "id": "8sp6LOpYU00S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import phoenix as px\n",
        "session = px.launch_app()"
      ],
      "metadata": {
        "id": "V5_q-eG3VZe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
        "from phoenix.otel import register\n",
        "\n",
        "tracer_provider = register()\n",
        "LlamaIndexInstrumentor().instrument(tracer_provider=tracer_provider)"
      ],
      "metadata": {
        "id": "zOqsUfWMVfZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "user0_docs = SimpleDirectoryReader(\n",
        "    input_files=[\"./dataset/user0/\"]\n",
        "    ).load_data()\n",
        "\n",
        "# build index\n",
        "user_docs_index = VectorStoreIndex.from_documents(user0_docs, show_progress=True)\n",
        "\n",
        "\n",
        "# persist index, JWTODO, do this later\n",
        "#lyft_index.storage_context.persist(persist_dir=\"./storage/lyft\")\n",
        "#uber_index.storage_context.persist(persist_dir=\"./storage/uber\")"
      ],
      "metadata": {
        "id": "D_mh3HUAVpTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user0_engine = user0_docs_index.as_query_engine(similarity_top_k=3, llm=llm)"
      ],
      "metadata": {
        "id": "DCSCScnqVvnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine_tools = [\n",
        "    QueryEngineTool(\n",
        "        query_engine=user0_engine,\n",
        "        metadata=ToolMetadata(\n",
        "            name=\"user0_cover_letter\",\n",
        "            description=(\n",
        "                \"build a cover letter from user profile and job position.\"\n",
        "            ),\n",
        "        ),\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "H_7VCLovV1MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = ReActAgent.from_tools(\n",
        "    query_engine_tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    max_turns=10,\n",
        ")"
      ],
      "metadata": {
        "id": "yFZYzDQXV5OH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(\"Could you build a cover letter that presents a strong case on why the applicant is a good candidate for the position?\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "id": "HxHwoaU_WBES"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}